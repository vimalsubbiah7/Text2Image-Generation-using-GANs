{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flowershd5dataset', 'flowershd5words']\n",
      "['flowers.hdf5']\n",
      "['flowers.hdf5.words']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "print(os.listdir(\"../input/flowershd5dataset/flowers-hd5/data/flowers/\"))\n",
    "print(os.listdir(\"../input/flowershd5words/\"))\n",
    "hdf5_fpath = \"../input/flowershd5dataset/flowers-hd5/data/flowers/flowers.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported!\n"
     ]
    }
   ],
   "source": [
    "#All imports are here\n",
    "\n",
    "import io\n",
    "import h5py\n",
    "import argparse\n",
    "import torch\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from datetime import timedelta\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "print(\"All libraries imported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'train', 'valid']\n",
      "\n",
      "No. of items in test =  5775\n",
      "\n",
      "No. of items in train =  29390\n",
      "\n",
      "No. of items in valid =  5780\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File(hdf5_fpath)\n",
    "\n",
    "print(list(f))\n",
    "print(\"\\nNo. of items in test = \",len(list(f['test'])))\n",
    "print(\"\\nNo. of items in train = \",len(list(f['train'])))\n",
    "print(\"\\nNo. of items in valid = \",len(list(f['valid'])))\n",
    "\n",
    "#print(\"\\n\\ntest = \\n\",list(f['test']))\n",
    "\n",
    "#print(\"\\n\\ntrain = \\n\",list(f['train']))\n",
    "\n",
    "#print(\"\\n\\nvalid = \\n\",list(f['valid']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BOTTOM-UP approach ahead!!!**\n",
    "\n",
    "The code in the next cell follows bottom up execution flow, to understand which method is getting called when start from the last part i.e., **runtime.py** code snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating fresh params for discriminator\n",
      "creating fresh params for generator\n",
      "***Calling Nearest Neighbour***\n",
      "start creating data for NN test source_flowers_only_nn_data.pl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:32: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish loading data for NN test\n",
      "*** Inside train() func ***\n",
      "*** Inside _train_gan() func ***\n",
      "Epoch: 0, d_loss= 1.597840, g_loss= 35.143642, ccaD(X)= 0.465871, D(G(X))= 0.278243\n",
      "Epoch: 0, d_loss= 1.632822, g_loss= 31.784142, ccaD(X)= 0.343231, D(G(X))= 0.152077\n",
      "Epoch: 0, d_loss= 1.296407, g_loss= 29.608517, ccaD(X)= 0.460121, D(G(X))= 0.170177\n",
      "Epoch: 0, d_loss= 1.084778, g_loss= 27.783548, ccaD(X)= 0.668340, D(G(X))= 0.360078\n",
      "Epoch: 0, d_loss= 1.160040, g_loss= 26.953245, ccaD(X)= 0.427077, D(G(X))= 0.112844\n",
      "Epoch: 0, d_loss= 1.621036, g_loss= 26.598480, ccaD(X)= 0.319601, D(G(X))= 0.150473\n",
      "Epoch: 0, d_loss= 1.323243, g_loss= 27.622395, ccaD(X)= 0.684250, D(G(X))= 0.505825\n",
      "Epoch: 0, d_loss= 1.137201, g_loss= 25.770273, ccaD(X)= 0.741155, D(G(X))= 0.439747\n",
      "Epoch: 0, d_loss= 1.016184, g_loss= 25.313845, ccaD(X)= 0.717296, D(G(X))= 0.356429\n",
      "Epoch: 0, d_loss= 1.117015, g_loss= 24.602095, ccaD(X)= 0.592253, D(G(X))= 0.314260\n",
      "Epoch: 0, d_loss= 1.018412, g_loss= 25.094715, ccaD(X)= 0.506476, D(G(X))= 0.153499\n",
      "Epoch: 0, d_loss= 1.503821, g_loss= 26.441486, ccaD(X)= 0.791984, D(G(X))= 0.619417\n",
      "Epoch: 0, d_loss= 1.223743, g_loss= 24.606207, ccaD(X)= 0.506988, D(G(X))= 0.317549\n",
      "Epoch: 0, d_loss= 0.872819, g_loss= 25.804626, ccaD(X)= 0.571174, D(G(X))= 0.176823\n",
      "Epoch: 0, d_loss= 1.196656, g_loss= 24.139040, ccaD(X)= 0.431391, D(G(X))= 0.139394\n",
      "Epoch: 0, d_loss= 1.147467, g_loss= 26.522066, ccaD(X)= 0.439686, D(G(X))= 0.161546\n",
      "Epoch: 0, d_loss= 0.975728, g_loss= 24.542603, ccaD(X)= 0.507873, D(G(X))= 0.135726\n",
      "Epoch: 0, d_loss= 1.070628, g_loss= 27.403028, ccaD(X)= 0.817923, D(G(X))= 0.433313\n",
      "Epoch: 0, d_loss= 1.219452, g_loss= 26.456051, ccaD(X)= 0.604813, D(G(X))= 0.413407\n",
      "Epoch: 0, d_loss= 1.341594, g_loss= 28.113733, ccaD(X)= 0.775458, D(G(X))= 0.539274\n",
      "Epoch: 0, d_loss= 1.222177, g_loss= 26.555063, ccaD(X)= 0.689386, D(G(X))= 0.474067\n",
      "Epoch: 0, d_loss= 1.223940, g_loss= 24.865116, ccaD(X)= 0.404393, D(G(X))= 0.160644\n",
      "Epoch: 0, d_loss= 1.113203, g_loss= 26.193768, ccaD(X)= 0.524456, D(G(X))= 0.272454\n",
      "*** Calling test() ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:672: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:673: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:677: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fake_source shape:  torch.Size([128, 3, 64, 64])\n",
      "text description:  these flowers have yellow layered petals with green stamen in the center of it.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:672: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:673: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:677: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fake_source shape:  torch.Size([128, 3, 64, 64])\n",
      "text description:  these flowers have yellow layered petals with green stamen in the center of it.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "combined text:  0 original sentence:  these flowers have yellow layered petals with green stamen in the center of it.\n",
      " nn_sentences:  ['this flower has yellow center and a fringe of very thin yellow hair-like petals.\\n', 'this flower is green and pink in color, with petals that are pointed.\\n']\n",
      "\n",
      "combined text:  1 original sentence:  the flower shown has small yellow petals with yellow pistil\n",
      " nn_sentences:  ['the round yellow petals cover over the stamen and the pistil of the flower.\\n', 'this flower has a long pedicel with many buds forming from it. the buds have yellow petals.\\n']\n",
      "\n",
      "combined text:  2 original sentence:  this flower has small orange petals with small stamens.\n",
      " nn_sentences:  ['this purple flower has long thin hair like petals and sits a top a green spiky bulb.\\n', 'this flower has petals that are yellow and has green stamen\\n']\n",
      "\n",
      "combined text:  3 original sentence:  the flower has orange and red petals with thin orange filament in the center.\n",
      " nn_sentences:  ['the pretty flower has two orange petals and one blue that make it look like some kind of bird.\\n', 'this pink flower has long thin petals and a green pedicel.\\n']\n",
      "\n",
      "combined text:  4 original sentence:  a flower with clustered red and pink flowers which has a central cluster of dark red stamen.\n",
      " nn_sentences:  ['there are two flies enjoying the sweet nectar of this lavender wild flower.\\n', 'this flower has tall, spiky orange petals with thick pointy green leaves.\\n']\n",
      "\n",
      "combined text:  5 original sentence:  this flower has a center clump of yellow stamen surrounded by a couple of layers of pink and white petals with rounded edges.\n",
      " nn_sentences:  ['this purple flower has long thin hair like petals and sits a top a green spiky bulb.\\n', 'flower with hair thin purple petals above a large spiky sepal.\\n']\n",
      "\n",
      "combined text:  6 original sentence:  this flower has petals that are red with yellow stamen\n",
      " nn_sentences:  ['this flower has a globe like shape with lots of small blue tubular petals.\\n', 'this flower is green and pink in color, with petals that are pointed.\\n']\n",
      "\n",
      "combined text:  7 original sentence:  this flower is white and purple in color, with petals that are spotted on the inside.\n",
      " nn_sentences:  ['this flower has a wide yellow center and long orange petals with serrated tips.\\n', 'this flower has petals that are yellow and are very thin\\n']\n",
      "\n",
      "combined text:  8 original sentence:  this flower has large red and white petals with a long white pistil.\n",
      " nn_sentences:  ['this flower has petals that are pink and has yellow spots\\n', 'flower with hair thin purple petals above a large spiky sepal.\\n']\n",
      "\n",
      "combined text:  9 original sentence:  this flower has a dark red petal and a yellow and red stamen\n",
      " nn_sentences:  ['this flower is green and pink in color, with petals that are pointed.\\n', 'this flower is pink and red in color, and has petals that are drooping down.\\n']\n",
      "\n",
      "combined text:  10 original sentence:  this flower has petals that are pink and has white lines\n",
      " nn_sentences:  ['flower with hair thin purple petals above a large spiky sepal.\\n', 'this flower is yellow in color, and has petals that are wrapped closely around the ovary.\\n']\n",
      "\n",
      "combined text:  11 original sentence:  a flower with purple flowers and now visible pistils.\n",
      " nn_sentences:  ['this purple flower has long thin hair like petals and sits a top a green spiky bulb.\\n', 'this flower has white petals as well as a white pistil.\\n']\n",
      "\n",
      "combined text:  12 original sentence:  the flower has petals that are stacked and burgundy with yellow tips.\n",
      " nn_sentences:  ['the petals of this flower are pink with purple stripes and the pistil is yellow\\n', 'this flower is green and pink in color, with petals that are pointed.\\n']\n",
      "\n",
      "combined text:  13 original sentence:  this is a red double flower that has soft petals and yellow stamens in the center.\n",
      " nn_sentences:  ['this flower is green and pink in color, with petals that are pointed.\\n', 'the flower has petals that are yellow with green pedicel.\\n']\n",
      "\n",
      "combined text:  14 original sentence:  this flower has petals that are white and has a pink center\n",
      " nn_sentences:  ['an array of many sets of long thin yellow petals circles around a cluster of orange stamens, with several petals curling up around the stamens.\\n', 'this flower has petals that are burgundy with white and yellow in center.\\n']\n",
      "\n",
      "combined text:  15 original sentence:  this flower has petals that are white and has purple spots\n",
      " nn_sentences:  ['this flower has petals that are yellow and very thing\\n', 'this flower is black, orange, and green in color, with petals that are pointed.\\n']\n",
      "\n",
      "combined text:  16 original sentence:  the flower shown has purple and white petals, and white anthers.\n",
      " nn_sentences:  ['this flower is green and pink in color, with petals that are pointed.\\n', 'this flower is red and pink in color, with petals that are drooping down.\\n']\n",
      "\n",
      "combined text:  17 original sentence:  this flower has petals that are red and has yellow stamen\n",
      " nn_sentences:  ['this flower has petals that are white and has yellow stamen\\n', 'this flower is yellow in color, with petals that are rounded.\\n']\n",
      "\n",
      "combined text:  18 original sentence:  the petals of the flower are a vibrant red, with some petals having dark black spots.\n",
      " nn_sentences:  ['this flower is white in color, with one large curled petal.\\n', 'petals are light brown in color,stamens are white in color\\n']\n",
      "\n",
      "combined text:  19 original sentence:  a pink and white flower with large curved petals and tiny yellow stamen.\n",
      " nn_sentences:  ['flower with hair thin purple petals above a large spiky sepal.\\n', 'a large group of white and blue flowers and a green stem.\\n']\n",
      "\n",
      "combined text:  20 original sentence:  the flower has thin pink petals that also has white middles.\n",
      " nn_sentences:  ['this flower is white in color, with one large curled petal.\\n', 'this flower is green and pink in color, with petals that are pointed.\\n']\n",
      "\n",
      "combined text:  21 original sentence:  this flower has petals that are white and many white stamen.\n",
      " nn_sentences:  ['the flower shown has small bunches of long skinny blue petals.\\n', 'this purple flower has long thin hair like petals and sits a top a green spiky bulb.\\n']\n",
      "\n",
      "combined text:  22 original sentence:  this flower has multicolored petals with notched yellow edges and a deeper red coloring close to the center.\n",
      " nn_sentences:  ['this flower has protruding white stamen with yellow anther surrounded by several large white petals with yellow accents.\\n', \"light pink petals and a green sepal support this flower's green stamen.\\n\"]\n",
      "\n",
      "combined text:  23 original sentence:  this flower has petals that are overlapping with a burgundy layer under a layer of white petals with a burgundy spot.\n",
      " nn_sentences:  ['the rounded yellow petals of this flower are layered around each other in such as way as to make the flower appear like a little ball on the end of the pedicel.\\n', 'this flower has petals that are yellow and has green stamen\\n']\n",
      "\n",
      "combined text:  24 original sentence:  this flower has red petals with yellow tips surrounding several red pistils.\n",
      " nn_sentences:  ['this flower is white and pink in color, with petals that are striped.\\n', 'this flower has petals that are yellow and are very thin\\n']\n",
      "\n",
      "combined text:  25 original sentence:  this flower has a ring of rounded bright yellow petals surrounding a small green pistil and yellow stamen.\n",
      " nn_sentences:  ['this flower is white in color, with one large curled petal.\\n', 'a flower that is surround by pointed leaves that are green.\\n']\n",
      "\n",
      "combined text:  26 original sentence:  this flower has five tapered pink petals surrounding five rounded white petals.\n",
      " nn_sentences:  ['this flower has petals that are yellow and has green stamen\\n', 'this flower is green and pink in color, with petals that are pointed.\\n']\n",
      "\n",
      "combined text:  27 original sentence:  this flower has petals that are yellow and has white tips\n",
      " nn_sentences:  ['this flower has petals that are pink with orange stamen\\n', 'the petals on this flower are mostly hazy yellow in color and the inner stamen is the color yellow .\\n']\n",
      "\n",
      "combined text:  28 original sentence:  a flower with long petals that curl outwards and are purple.\n",
      " nn_sentences:  ['this flower has many spiky green leaves along with a bunch of very thin purple petals.\\n', 'a single, large, wrinkled yellow petal surrounding a center of small stamen with black anthers.\\n']\n",
      "\n",
      "combined text:  29 original sentence:  this flower has pale purple and ruffle-edges petals which are large and soft.\n",
      " nn_sentences:  ['this flower has a disk shaped head with many long purple petals.\\n', 'this white flower has a white stigma with an green pedicel and lime sepal.\\n']\n",
      "\n",
      "combined text:  30 original sentence:  the petals of this flower are yellow with a short stigma\n",
      " nn_sentences:  ['a large group of white and blue flowers and a green stem.\\n', 'this flower is green and pink in color, with petals that are pointed.\\n']\n",
      "\n",
      "combined text:  31 original sentence:  this flower is white and blue in color, with petals that are multi colored.\n",
      " nn_sentences:  ['a flower with short and wide petals that are yellow.\\n', 'this flower has white petals as well as a white pistil.\\n']\n",
      "\n",
      "combined text:  32 original sentence:  this flower has a yellow stigma and white dropping petals.\n",
      " nn_sentences:  ['this flower is green and pink in color, with petals that are pointed.\\n', 'this flower is orange and pink in color, with petals that are drooping down.\\n']\n",
      "\n",
      "combined text:  33 original sentence:  this flower has upturned layers of pink petals with tapered tips.\n",
      " nn_sentences:  ['this flower has petals that are purple with patches of white\\n', 'this flower is green and pink in color, with petals that are pointed.\\n']\n",
      "\n",
      "combined text:  34 original sentence:  this flower has large purple petals, and no visible stamen in sight\n",
      " nn_sentences:  ['this flower has a green pistil with long and pointy purple petals.\\n', 'this flower has wide spread purple petals with green near the pollen tube.\\n']\n",
      "\n",
      "combined text:  35 original sentence:  this flower has five petals that are yellow in the middle with a white outline.\n",
      " nn_sentences:  ['this flower has petals that are yellow and has black lines\\n', 'this flower is green and pink in color, with petals that are pointed.\\n']\n",
      "\n",
      "combined text:  36 original sentence:  a yellow and white flower with large drooping petals and orange stamen.\n",
      " nn_sentences:  ['this flower is green and pink in color, with petals that are pointed.\\n', 'this is an orange flower brown spots on the petals with long, thin stamens.\\n']\n",
      "\n",
      "combined text:  37 original sentence:  this yellow flower has five petals that appear to form a star shape.\n",
      " nn_sentences:  ['this flower is white in color, with one large curled petal.\\n', 'this flower has many spiky green leaves along with a bunch of very thin purple petals.\\n']\n",
      "\n",
      "combined text:  38 original sentence:  this flower has a green pedicel and white petels with a yellow pistil and stamen.\n",
      " nn_sentences:  ['this white flower has a white stigma with an green pedicel and lime sepal.\\n', 'this particular flower has petals that are long and gray and light red\\n']\n",
      "\n",
      "combined text:  39 original sentence:  this flower features a white ovary surrounded by a layer of broad purple petals.\n",
      " nn_sentences:  ['this flower has petals that are yellow and has black lines\\n', 'this purple flower has long thin hair like petals and sits a top a green spiky bulb.\\n']\n",
      "\n",
      "combined text:  40 original sentence:  this flower has large white petals with a wrinkled texture and a yellow pistil surrounded by orange stamen.\n",
      " nn_sentences:  ['this flower has petals that are orange and very thin\\n', 'this pink flower has long thin petals and a green pedicel.\\n']\n",
      "\n",
      "combined text:  41 original sentence:  a bright pink and white flower that is star shaped with rounded throats.\n",
      " nn_sentences:  ['the flower has one large lavender petals and three pink, with yellow sticks petals.\\n', 'the pretty flower has two orange petals and one blue that make it look like some kind of bird.\\n']\n",
      "\n",
      "combined text:  42 original sentence:  this flower is red in color, with only one large petal.\n",
      " nn_sentences:  ['the petals of the flower have not fully opened, and the petals are a solid bright yellow color.\\n', 'this flower is white in color, with one large curled petal.\\n']\n",
      "\n",
      "combined text:  43 original sentence:  this flower has a large upright green pistils and yellow stamen with a layer of wavy white filaments and oblong petals.\n",
      " nn_sentences:  ['this flower is white in color, with one large curled petal.\\n', 'the flower has light pink petals with pink veins and white stamens.\\n']\n",
      "\n",
      "combined text:  44 original sentence:  this flower has white petals as well as a purple sepal.\n",
      " nn_sentences:  ['this flower has green petals as well as a purple stamen.\\n', 'this flower is yellow in color, with petals that are rounded.\\n']\n",
      "\n",
      "combined text:  45 original sentence:  layers of thick pink and white petals encase the bright yellow stamens.\n",
      " nn_sentences:  ['this flower grows fluffy blue petals in a round formation.\\n', 'this flower has petals that are yellow and are bunched together\\n']\n",
      "\n",
      "combined text:  46 original sentence:  this flower has petals that are lavender and is slightly drooping in the center.\n",
      " nn_sentences:  ['the flower shown has small bunches of long skinny blue petals.\\n', 'the flower shown has small bunches of long skinny blue petals.\\n']\n",
      "\n",
      "combined text:  47 original sentence:  this flower has petals that are white and has green lines\n",
      " nn_sentences:  ['this flower has many petals that are blue and white spikes in a pompom shape.\\n', 'this flower has the butterfly shaped purple petals on the purplish green sepals\\n']\n",
      "\n",
      "combined text:  48 original sentence:  this flower contains small white petals surrounding long white delicate stamens.\n",
      " nn_sentences:  ['the flower has one large lavender petals and three pink, with yellow sticks petals.\\n', 'this flower is green and pink in color, with petals that are pointed.\\n']\n",
      "\n",
      "combined text:  49 original sentence:  this flower has red and yellow petals as well as a yellow stamen.\n",
      " nn_sentences:  ['this flower is brown, orange and black in color with sharp petals.\\n', 'this flower has very short green pointed sepals underneath a single layer of yellow oblong petals in a ring.\\n']\n",
      "\n",
      "combined text:  50 original sentence:  this flower has a dark purple sepals and pedicel along with small yellow petals.\n",
      " nn_sentences:  ['this flower is yellow in color, and has petals that are wavy and wrinkled.\\n', 'this flower has petals that are red and has yellow stamen\\n']\n",
      "\n",
      "combined text:  51 original sentence:  a flower with a tubular pink and red dotted petal, green sepals, and green pedicel\n",
      " nn_sentences:  ['this flower is brown, orange and black in color with sharp petals.\\n', 'this flower is green and pink in color, with petals that are pointed.\\n']\n",
      "\n",
      "combined text:  52 original sentence:  this flower has petals that are yellow with orange dots\n",
      " nn_sentences:  ['this flower has a red and yellow color scheme on its pedals and a white pistil.\\n', 'this flower has a star-shape with bright blue petals that have darker veins and a white pistil.\\n']\n",
      "\n",
      "combined text:  53 original sentence:  this flower is pink in color, and has petals that are oval shaped.\n",
      " nn_sentences:  ['this flower is white in color, with one large curled petal.\\n', 'this flower is green and pink in color, with petals that are pointed.\\n']\n",
      "\n",
      "combined text:  54 original sentence:  this flower is yellow and pink in color, with petals that are curled closely around the center.\n",
      " nn_sentences:  ['flower with hair thin purple petals above a large spiky sepal.\\n', 'this flower is green and pink in color, with petals that are pointed.\\n']\n",
      "\n",
      "combined text:  55 original sentence:  the petals on this flower are yellow in color and there are a large number of stamen.\n",
      " nn_sentences:  ['this flower has very short green pointed sepals underneath a single layer of yellow oblong petals in a ring.\\n', 'this flower has petals that are orange and blue and thin\\n']\n",
      "\n",
      "combined text:  56 original sentence:  this flower has purple petals and no visible outer stigma\n",
      " nn_sentences:  ['this flower has petals that are purple with green stamen\\n', 'this flower has petals that are burgundy with white and yellow in center.\\n']\n",
      "\n",
      "combined text:  57 original sentence:  this flower has petals that are red and has yellow stamen\n",
      " nn_sentences:  ['this flower has very short green pointed sepals underneath a single layer of yellow oblong petals in a ring.\\n', 'this flower is green and pink in color, with petals that are pointed.\\n']\n",
      "\n",
      "combined text:  58 original sentence:  this flowers has layers of thick pink petals with darker pink spots.\n",
      " nn_sentences:  ['this is an orange flower brown spots on the petals with long, thin stamens.\\n', 'a large group of white and blue flowers and a green stem.\\n']\n",
      "\n",
      "combined text:  59 original sentence:  this flower has purple petals with the inner ones very thin and stringy with purple pollen tube and a green stigma\n",
      " nn_sentences:  ['this flower is orange and pink in color, with petals that are drooping down.\\n', 'this flower features broad yellow petals surrounding the ovary in a ball like pattern.\\n']\n",
      "\n",
      "combined text:  60 original sentence:  this flower has large and upright stamens and pistil with a flat row of purple petals and filaments.\n",
      " nn_sentences:  ['this flower has small, smooth, rounded petals that are yellow in color.\\n', 'the thorny plant has a pink flower made of thin pink filaments.\\n']\n",
      "\n",
      "combined text:  61 original sentence:  this flower has a pale green and yellow center and very smooth pink petals.\n",
      " nn_sentences:  ['the flower has petals that are yellow with green pedicel.\\n', 'the petals are rounded in shape and are yellow folded in color\\n']\n",
      "\n",
      "combined text:  62 original sentence:  this flower has petals that are orange and has flowery stigma\n",
      " nn_sentences:  ['this flower has wide spread purple petals with green near the pollen tube.\\n', 'this flower is brown, orange and black in color with sharp petals.\\n']\n",
      "\n",
      "combined text:  63 original sentence:  this flower has white petals that have long and stringy purple stamen\n",
      " nn_sentences:  ['this white flower has a white stigma with an green pedicel and lime sepal.\\n', 'this flower is white in color, with one large curled petal.\\n']\n",
      "\n",
      "combined text:  64 original sentence:  this flower has a yellow center and layers of thick upturned white petals.\n",
      " nn_sentences:  ['this is a yellowish orange flower with many thin petals and a green, almost furry stem.\\n', 'this flower has four large pink petals which are slightly heart shaped and have leaflike veins.\\n']\n",
      "\n",
      "combined text:  65 original sentence:  this flower is red in color, with petals that are rounded.\n",
      " nn_sentences:  ['this flower has white petals as well as a white pistil.\\n', 'the flower shown has small bunches of long skinny blue petals.\\n']\n",
      "\n",
      "combined text:  66 original sentence:  this flower has petals that are yellow and has white edges\n",
      " nn_sentences:  ['the pretty flower has two orange petals and one blue that make it look like some kind of bird.\\n', 'this purple flower has long thin hair like petals and sits a top a green spiky bulb.\\n']\n",
      "\n",
      "combined text:  67 original sentence:  a tan paper-like appearance with a white and red stigma.\n",
      " nn_sentences:  ['this flower is green and pink in color, with petals that are pointed.\\n', 'this flower is green and pink in color, with petals that are pointed.\\n']\n",
      "\n",
      "combined text:  68 original sentence:  this flower has petals that are white and has yellow stamen\n",
      " nn_sentences:  ['this is a yellowish orange flower with many thin petals and a green, almost furry stem.\\n', 'this flower has petals that are yellow and very thing\\n']\n",
      "\n",
      "combined text:  69 original sentence:  this flower has petals that are red with yellow and white style\n",
      " nn_sentences:  ['petals are light brown in color,stamens are white in color\\n', 'this flower has petals that are burgundy with white and yellow in center.\\n']\n",
      "\n",
      "combined text:  70 original sentence:  this flower has petals that are purple with flowery stigma\n",
      " nn_sentences:  ['the flower has one large lavender petals and three pink, with yellow sticks petals.\\n', 'this flower is yellow in color, with petals that are very skinny.\\n']\n",
      "\n",
      "combined text:  71 original sentence:  the flower has light green petals that are oval, large and thin shaped.\n",
      " nn_sentences:  ['this flower is green and pink in color, with petals that are pointed.\\n', 'this flower is purple in color, and has petals that are very skinny.\\n']\n",
      "\n",
      "combined text:  72 original sentence:  this flower has a wide brown center surrounded by slightly tapered yellow petals,\n",
      " nn_sentences:  ['this flower has four very broad light pink petals with a yellow green center.\\n', 'the pointy purple petals of this flower sits on top of a thick white pedicel.\\n']\n",
      "\n",
      "combined text:  73 original sentence:  a flower that is pink and cream colored with white trim.\n",
      " nn_sentences:  ['an array of many sets of long thin yellow petals circles around a cluster of orange stamens, with several petals curling up around the stamens.\\n', 'this flower has petals that are yellow and has green stamen\\n']\n",
      "\n",
      "combined text:  74 original sentence:  a flower with ruffled purple petals and a central cluster of white long stamen.\n",
      " nn_sentences:  ['this flower has blue petals as well as a blue stamen.\\n', 'this flower is green and pink in color, with petals that are pointed.\\n']\n",
      "\n",
      "combined text:  75 original sentence:  this flower is pink and white in color, and has petals that are leaf like.\n",
      " nn_sentences:  ['each part of the flower, including the petals, pistil, stamen, sepals are all varying shades of dark to light green.\\n', 'this flower is yellow in color, and has petals that are wavy and wrinkled.\\n']\n",
      "\n",
      "combined text:  76 original sentence:  this flower has petals that are yellow and has a satellite shape\n",
      " nn_sentences:  ['the petals of this flower are pink and white with a long stigma\\n', 'this flower has long purple ribbed petals in a ring configuration.\\n']\n",
      "\n",
      "combined text:  77 original sentence:  this flower has petals that are purple and has white stamen\n",
      " nn_sentences:  ['this flower has white petals with purple tips and a prominent stamen.\\n', 'the flower has one large lavender petals and three pink, with yellow sticks petals.\\n']\n",
      "\n",
      "combined text:  78 original sentence:  this flower has frilly bright white petals with a orangish yellow center.\n",
      " nn_sentences:  ['this flower has petals that are white and has yellow shading\\n', \"the beautiful yellow flower is like a ball of sunshine with it's bright petals and dark green leaves.\\n\"]\n",
      "\n",
      "combined text:  79 original sentence:  the petals of this flower are orange with orange stamen.\n",
      " nn_sentences:  ['this flower is green and pink in color, with petals that are pointed.\\n', 'this flower has petals that are yellow and has green stamen\\n']\n",
      "\n",
      "combined text:  80 original sentence:  the petals on this flower are mostly white with long stringy stamen.\n",
      " nn_sentences:  ['this flower has a dome-like configuration of very small and skinny pink petals.\\n', 'this flower is green and pink in color, with petals that are pointed.\\n']\n",
      "\n",
      "combined text:  81 original sentence:  this is a large white flower with a concave center and a few stems coming up from it\n",
      " nn_sentences:  ['this flower is green and pink in color, with petals that are pointed.\\n', 'this flower is pink and yellow in color, with petals that are rounded.\\n']\n",
      "\n",
      "combined text:  82 original sentence:  this red flower has petals arranged as a circle with the clumsy stamens at the center\n",
      " nn_sentences:  ['this flower has spiky petals of orange and a purplish blue with spiky foliage.\\n', 'this flower is green and pink in color, with petals that are pointed.\\n']\n",
      "\n",
      "combined text:  83 original sentence:  this pink flower has many rows of overlapping petals with the prominent yellow stamens at the center\n",
      " nn_sentences:  ['this purple flower has long thin hair like petals and sits a top a green spiky bulb.\\n', 'this flower is green and pink in color, with petals that are pointed.\\n']\n",
      "\n",
      "combined text:  84 original sentence:  this flower has purple stamen and yellow and purple petals.\n",
      " nn_sentences:  ['this purple flower has long thin hair like petals and sits a top a green spiky bulb.\\n', 'this flower is yellow and blue in color, with petals that are skinny and pointed.\\n']\n",
      "\n",
      "combined text:  85 original sentence:  this flower has connected red petals are surrounding white stamen.\n",
      " nn_sentences:  ['this flower has a dark purple petal and a bright yellow stamen\\n', 'this flower has petals that are burgundy with white and yellow in center.\\n']\n",
      "\n",
      "combined text:  86 original sentence:  this flower has sparsely arranged petals that are bright yellow with dark red spots on them.\n",
      " nn_sentences:  ['the petals of the flower are pink in color with some white details.\\n', 'the flower is pink with fused petal that is soft, smooth and also forming a bell like shape\\n']\n",
      "\n",
      "combined text:  87 original sentence:  this flower is pink in color, and has petals that are heart shaped.\n",
      " nn_sentences:  ['this flower is green and pink in color, with petals that are pointed.\\n', 'this flower has long, tapered lavender petals around prominent brown stamen.\\n']\n",
      "\n",
      "combined text:  88 original sentence:  this flower has petals that are red and has yellow stamen\n",
      " nn_sentences:  ['this flower is white in color, with one large curled petal.\\n', 'the petals are yellow with anthers appearing as white.\\n']\n",
      "\n",
      "combined text:  89 original sentence:  this flower has petals that are red with yellow stamen\n",
      " nn_sentences:  ['this flower is green and pink in color, with petals that are pointed.\\n', 'this flower is green and pink in color, with petals that are pointed.\\n']\n",
      "\n",
      "combined text:  90 original sentence:  this flower is pink in color, with only one large petal.\n",
      " nn_sentences:  ['the pink petals form a deep bell shape upon a green receptacle.\\n', 'this flower is white in color, with one large curled petal.\\n']\n",
      "\n",
      "combined text:  91 original sentence:  this flower is made up of five pink petals that all have white tips and stripes.\n",
      " nn_sentences:  ['there are several light pink heart shaped petals, two light pink and yellow petals with maroon speckles, and prominent pink and green stamen.\\n', 'this flower is orange and black in color, with petals that are pointed.\\n']\n",
      "\n",
      "combined text:  92 original sentence:  this flower has a large funnel shaped petal with a yellow ovary and pink coloring.\n",
      " nn_sentences:  ['this flower has petals that are burgundy with white and yellow in center.\\n', 'this flower has white petals as well as a white pistil.\\n']\n",
      "\n",
      "combined text:  93 original sentence:  prominent large red petals surround yellow anthers with feathery appendages.\n",
      " nn_sentences:  ['the flower has one large lavender petals and three pink, with yellow sticks petals.\\n', 'the thorny plant has a pink flower made of thin pink filaments.\\n']\n",
      "\n",
      "combined text:  94 original sentence:  the petals of this flower are white and purple and the pedicel is green\n",
      " nn_sentences:  ['this flower has petals that are purple with shades of white\\n', 'this flower is green and pink in color, with petals that are pointed.\\n']\n",
      "\n",
      "combined text:  95 original sentence:  this flower is purple white and black in color, and has petals that are spotted.\n",
      " nn_sentences:  ['this flower has wide spread purple petals with green near the pollen tube.\\n', 'this flower has bright orange petals with pointed tips that are very sparsely arranged.\\n']\n",
      "\n",
      "combined text:  96 original sentence:  this flower is white and pink in color, with petals that are multi colored.\n",
      " nn_sentences:  ['this flower has very short green pointed sepals underneath a single layer of yellow oblong petals in a ring.\\n', 'this flower has white stamen, yellow anther filaments and white and pink petals.\\n']\n",
      "\n",
      "combined text:  97 original sentence:  this flower has petals that are pink and has shades of red\n",
      " nn_sentences:  ['the flower is pink with fused petal that is soft, smooth and also forming a bell like shape\\n', 'this flower has petals that are orange and blue and thin\\n']\n",
      "\n",
      "combined text:  98 original sentence:  the flower shown has red and orange petals which are its main feature\n",
      " nn_sentences:  ['this pink flower has long thin petals and a green pedicel.\\n', 'this pink flower has long thin petals and a green pedicel.\\n']\n",
      "\n",
      "combined text:  99 original sentence:  this yellow flower's deep green leaves are layered, and shaped exactly like it's sharp petals.\n",
      " nn_sentences:  ['the flower has petals that are yellow with green pedicel.\\n', 'this flower has very short green pointed sepals underneath a single layer of yellow oblong petals in a ring.\\n']\n",
      "\n",
      "combined text:  100 original sentence:  this flower has petals that are pink and has yellow stamen\n",
      " nn_sentences:  ['this flower has long purple petals which are shaped like thin ovals.\\n', 'the petals of this flower are yellow witha long stigma\\n']\n",
      "\n",
      "combined text:  101 original sentence:  this flower is yellow and white in color, with petals that are oval shaped.\n",
      " nn_sentences:  ['this pink flower has long thin petals and a green pedicel.\\n', 'this flower has very short green pointed sepals underneath a single layer of yellow oblong petals in a ring.\\n']\n",
      "\n",
      "combined text:  102 original sentence:  four bright yellow circular petals surrounding a brighter yellow stamen.\n",
      " nn_sentences:  ['the flower has skinny pointed purple petals, stamen, and pistils.\\n', 'this flower is green and pink in color, with petals that are pointed.\\n']\n",
      "\n",
      "combined text:  103 original sentence:  this flower has a small number of medium sized white cupped petals with rose bases.\n",
      " nn_sentences:  ['this flower has petals that are yellow and has green stamen\\n', 'this flower has multiple pink with dark pink markings petals and pink with dark pink and yellow and white petals.\\n']\n",
      "\n",
      "combined text:  104 original sentence:  this flower has a large pink flower and no visible stigma\n",
      " nn_sentences:  ['this flower is white and yellow in color, and has petals that are ruffled and wavy.\\n', 'this flower is white in color, with one large curled petal.\\n']\n",
      "\n",
      "combined text:  105 original sentence:  this flower is white and yellow in color, and has petals that are only yellow near the base of the ovary.\n",
      " nn_sentences:  ['this flower has petals that are yellow and are very stringy\\n', 'this flower has white petals as well as a yellow pistil.\\n']\n",
      "\n",
      "combined text:  106 original sentence:  this flower has clusters of orange and red petals surrounding brown-tinted stamen.\n",
      " nn_sentences:  ['the pretty flower has two orange petals and one blue that make it look like some kind of bird.\\n', 'the flower has light pink petals with pink veins and white stamens.\\n']\n",
      "\n",
      "combined text:  107 original sentence:  this is a bright red flower with a large white pistil.\n",
      " nn_sentences:  ['this flower has light pink petals with purple ridges, coming off of a green stem.\\n', 'this flower is yellow in color, and has petals that are wavy and wrinkled.\\n']\n",
      "\n",
      "combined text:  108 original sentence:  this flower is pink in color, with petals that are dark near the center.\n",
      " nn_sentences:  ['this flower has a round center and down-turned petals of pink.\\n', 'this flower has petals that are think and yellow with yellow stamen.\\n']\n",
      "\n",
      "combined text:  109 original sentence:  this flower has a wide yellow center and long thin white petals.\n",
      " nn_sentences:  ['this flower is yellow in color, with petals that are skinny and long.\\n', 'this flower is green and pink in color, with petals that are pointed.\\n']\n",
      "\n",
      "combined text:  110 original sentence:  large white pedals with rounded ends with yellow centers made up of many stamen with a long pointed green leaf.\n",
      " nn_sentences:  ['this flower is green and pink in color, with petals that are pointed.\\n', 'the petals of the flower fold inward to form a circle and are orange in color with black spots.\\n']\n",
      "\n",
      "combined text:  111 original sentence:  a vibrant large trumpet shaped pink bloom with several overlapping ruffled large petals with no visible stamen or pistil.\n",
      " nn_sentences:  ['this flower grows fluffy blue petals in a round formation.\\n', 'this flower has long, tapered lavender petals around prominent brown stamen.\\n']\n",
      "\n",
      "combined text:  112 original sentence:  the varying pink petals complement the beautiful green pollen tube.\n",
      " nn_sentences:  ['this flower has petals that are burgundy with white and yellow in center.\\n', 'this purple flower has long thin hair like petals and sits a top a green spiky bulb.\\n']\n",
      "\n",
      "combined text:  113 original sentence:  the petals on this flower are vibrant pink and the pistils are yellow\n",
      " nn_sentences:  ['this flower is green and pink in color, with petals that are pointed.\\n', 'the flower has a smooth purple petal with a green pedicel\\n']\n",
      "\n",
      "combined text:  114 original sentence:  this flower has large white petals with no visible stamen in the center of it\n",
      " nn_sentences:  ['the petals of the flower are light pink in color and have a green sepal.\\n', 'this flower is yellow in color, with petals that are skinny and long.\\n']\n",
      "\n",
      "combined text:  115 original sentence:  this flower is pink in color, with petals that are layered.\n",
      " nn_sentences:  ['this purple flower has long thin hair like petals and sits a top a green spiky bulb.\\n', 'this flower is green and pink in color, with petals that are pointed.\\n']\n",
      "\n",
      "combined text:  116 original sentence:  this flower has a green pedicel with lavender petals that are polka dotted with dark purple dots.\n",
      " nn_sentences:  ['this flower has layers of bright orange petals with rounded edges.\\n', 'these small red flowers have yellow centers and dark red stripes\\n']\n",
      "\n",
      "combined text:  117 original sentence:  an orange flower with separate petals that arranged in disc like manner around stamen\n",
      " nn_sentences:  ['the pointy purple petals of this flower sits on top of a thick white pedicel.\\n', 'this flower has petals that are orange and blue and thin\\n']\n",
      "\n",
      "combined text:  118 original sentence:  the spherical yellow flower has petals that are soft, smooth and separately and densely arranged on top of the pedicel\n",
      " nn_sentences:  ['this flower is green and pink in color, with petals that are pointed.\\n', 'flower with hair thin purple petals above a large spiky sepal.\\n']\n",
      "\n",
      "combined text:  119 original sentence:  the fan shaped petals are pink towards the edges and bright yellow in the center around the white stamen.\n",
      " nn_sentences:  ['this flower has petals that are pink and has red stamen\\n', 'the pedicel is brown in color ,petals are yellow in color\\n']\n",
      "\n",
      "combined text:  120 original sentence:  this flower is white and pink in color, and has petals that are oval shaped.\n",
      " nn_sentences:  ['this flower is green and pink in color, with petals that are pointed.\\n', 'this flower has petals that are yellow and very thing\\n']\n",
      "\n",
      "combined text:  121 original sentence:  this is a pink flower with pointed petals and a yellow style.\n",
      " nn_sentences:  ['this flower has very short green pointed sepals underneath a single layer of yellow oblong petals in a ring.\\n', 'this flower is green and pink in color, with petals that are pointed.\\n']\n",
      "\n",
      "combined text:  122 original sentence:  this flower is yellow in color, and has petals that are rounded.\n",
      " nn_sentences:  ['this flower is green and pink in color, with petals that are pointed.\\n', 'this flower is green and pink in color, with petals that are pointed.\\n']\n",
      "\n",
      "combined text:  123 original sentence:  the petals of the flower are red in color and are curled along the edges.\n",
      " nn_sentences:  ['the flower is pink with fused petal that is soft, smooth and also forming a bell like shape\\n', 'the round yellow petals cover over the stamen and the pistil of the flower.\\n']\n",
      "\n",
      "combined text:  124 original sentence:  this flower has petals that are white with yellow stamen\n",
      " nn_sentences:  ['the flower is pink with fused petal that is soft, smooth and also forming a bell like shape\\n', 'this flower is white in color, with one large curled petal.\\n']\n",
      "\n",
      "combined text:  125 original sentence:  this flower is orange and yellow in color, with petals that are oval shaped.\n",
      " nn_sentences:  ['this flower is white in color, with one large curled petal.\\n', 'this flower has blue petals as well as a blue stamen.\\n']\n",
      "\n",
      "combined text:  126 original sentence:  this flower has red petals as well as a red stamen.\n",
      " nn_sentences:  ['this flower has petals that are purple and very flat\\n', 'this flower has petals that are yellow and has green stamen\\n']\n",
      "\n",
      "combined text:  127 original sentence:  this long slender flower has short stacked pale pink petals.\n",
      " nn_sentences:  ['this flower has long yellow petals and no visible outer stamen\\n', 'an array of many sets of long thin yellow petals circles around a cluster of orange stamens, with several petals curling up around the stamens.\\n']\n",
      "*** end of testing ***\n",
      "Running GAN-CLS took 0:06:37\n"
     ]
    }
   ],
   "source": [
    "################ nn.py (NearestNeighbour) ###################\n",
    "\n",
    "class NearestNeighbor:\n",
    "    def __init__(self, dataset, source, cuda, ngf):\n",
    "        self.dataset = dataset\n",
    "        data = None\n",
    "        representation = None\n",
    "        labels = []\n",
    "        embeddings = []\n",
    "        path = ''\n",
    "        data_path = path + 'source_{}_nn_data.pl'.format(source)\n",
    "        labels_path = path + 'source_{}_nn_labels.pl'.format(source)\n",
    "        nbrs_path = path + 'source_{}_nn.pl'.format(source)\n",
    "        embeddings_path = path + 'source_{}_nn_embeddings.pl'.format(source)\n",
    "        self.model = gan_factory.generator_factory('vae', ngf, False)\n",
    "        if cuda:\n",
    "            self.model = self.model.cuda()\n",
    "        #self.model.load_state_dict(torch.load('./checkpoints/flowers_autoencoder/gen.pth'))\n",
    "\n",
    "        if os.path.exists(data_path):\n",
    "            print('start loading data for NN test {}'.format(data_path))\n",
    "            data = pickle.load(open(data_path, 'rb'))\n",
    "            labels = pickle.load(open(labels_path, 'rb'))\n",
    "            nbrs = pickle.load(open(nbrs_path, 'rb'))\n",
    "            embeddings = pickle.load(open(embeddings_path, 'rb'))\n",
    "        else:\n",
    "            print('start creating data for NN test {}'.format(data_path))\n",
    "            for i, sample in enumerate(dataset):\n",
    "                #print(\"**** iter i = \",i)\n",
    "                if data is None:\n",
    "                    data = sample['right_images'].numpy()\n",
    "                    data_var = Variable(sample['right_images'].float(), volatile=True)\n",
    "                    if cuda:\n",
    "                        data_var = data_var.cuda()\n",
    "                    representation = self.model.encoder_only(data_var).data.cpu().numpy()\n",
    "                    labels = sample['txt']\n",
    "                    embeddings = sample['right_embed']\n",
    "                else:\n",
    "                    data = np.append(data, sample['right_images'].numpy(), axis=0)\n",
    "                    data_var = Variable(sample['right_images'].float(), volatile=True)\n",
    "                    if cuda:\n",
    "                        data_var = data_var.cuda()\n",
    "                    representation = np.append(representation, self.model.encoder_only(data_var).data.cpu().numpy(),\n",
    "                                               axis=0)\n",
    "                    labels += sample['txt']\n",
    "                    embeddings = np.append(embeddings, sample['right_embed'].numpy(), axis=0)\n",
    "            nbrs = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(representation.reshape(-1, 228))\n",
    "            pickle.dump(data, open(data_path, 'wb'))\n",
    "            pickle.dump(labels, open(labels_path, 'wb'))\n",
    "            pickle.dump(nbrs, open(nbrs_path, 'wb'))\n",
    "            pickle.dump(embeddings, open(embeddings_path, 'wb'))\n",
    "        print('finish loading data for NN test')\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.nbrs = nbrs\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "    def get_text(self, samples, limit=-1):\n",
    "        text_results, _, _ = self.get_text_and_images_and_embedding(samples, limit)\n",
    "        return text_results\n",
    "\n",
    "    def get_text_and_images(self, samples, limit):\n",
    "        text_results, image_results, _ = self.get_text_and_images_and_embedding(samples, limit)\n",
    "        return text_results, image_results\n",
    "\n",
    "    def get_text_and_images_and_embedding(self, samples, limit=-1):\n",
    "        samples_embedding = self.model.encoder_only(samples).data.cpu().numpy().reshape(-1, 228)\n",
    "        if limit != -1:\n",
    "            samples_embedding = samples_embedding[:limit]\n",
    "        distances, indices = self.nbrs.kneighbors(samples_embedding)\n",
    "        text_results = [self.labels[index] for index in indices[:, 0]]\n",
    "        image_results = [self.data[index] for index in indices[:, 0]]\n",
    "        embedding_results = [self.embeddings[index] for index in indices[:, 0]]\n",
    "        return text_results, image_results, embedding_results\n",
    "    \n",
    "################ nn.py (NearestNeighbour) ends here ###################\n",
    "\n",
    "################ txt2image_dataset.py ###################\n",
    "\n",
    "class Text2ImageDataset(Dataset):\n",
    "\n",
    "    def __init__(self, datasetFile, transform=None, split=0):\n",
    "        self.datasetFile = datasetFile\n",
    "        self.transform = transform\n",
    "        self.dataset = None\n",
    "        self.dataset_keys = None\n",
    "        self.split = 'train' if split == 0 else 'valid' if split == 1 else 'test'\n",
    "        self.h5py2int = lambda x: int(np.array(x))\n",
    "\n",
    "    def __len__(self):\n",
    "        f = h5py.File(self.datasetFile, 'r')\n",
    "        self.dataset_keys = [str(k) for k in f[self.split].keys()]\n",
    "        length = len(f[self.split])\n",
    "        f.close()\n",
    "\n",
    "        return length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.dataset is None:\n",
    "            self.dataset = h5py.File(self.datasetFile, mode='r')\n",
    "            self.dataset_keys = [str(k) for k in self.dataset[self.split].keys()]\n",
    "\n",
    "        example_name = self.dataset_keys[idx]\n",
    "        example = self.dataset[self.split][example_name]\n",
    "\n",
    "        # pdb.set_trace()\n",
    "\n",
    "        right_image = bytes(np.array(example['img']))\n",
    "        right_embed = np.array(example['embeddings'], dtype=float)\n",
    "        wrong_image = bytes(np.array(self.find_wrong_image(example['class'])))\n",
    "        inter_embed = np.array(self.find_inter_embed())\n",
    "\n",
    "        right_image = Image.open(io.BytesIO(right_image)).resize((64, 64))\n",
    "        wrong_image = Image.open(io.BytesIO(wrong_image)).resize((64, 64))\n",
    "\n",
    "        right_image = self.validate_image(right_image)\n",
    "        wrong_image = self.validate_image(wrong_image)\n",
    "\n",
    "        txt = np.array(example['txt']).astype(str)\n",
    "        class_ = np.array(example['class']).astype(str)\n",
    "\n",
    "        sample = {\n",
    "                'right_images': torch.FloatTensor(right_image),\n",
    "                'right_embed': torch.FloatTensor(right_embed),\n",
    "                'wrong_images': torch.FloatTensor(wrong_image),\n",
    "                'inter_embed': torch.FloatTensor(inter_embed),\n",
    "                'txt': str(txt),\n",
    "                'class': str(class_)\n",
    "                 }\n",
    "\n",
    "        sample['right_images'] = sample['right_images'].sub_(127.5).div_(127.5)\n",
    "        sample['wrong_images'] =sample['wrong_images'].sub_(127.5).div_(127.5)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def find_wrong_image(self, category):\n",
    "        idx = np.random.randint(len(self.dataset_keys))\n",
    "        example_name = self.dataset_keys[idx]\n",
    "        example = self.dataset[self.split][example_name]\n",
    "        _category = example['class']\n",
    "\n",
    "        if _category != category:\n",
    "            return example['img']\n",
    "\n",
    "        return self.find_wrong_image(category)\n",
    "\n",
    "    def find_inter_embed(self):\n",
    "        idx = np.random.randint(len(self.dataset_keys))\n",
    "        example_name = self.dataset_keys[idx]\n",
    "        example = self.dataset[self.split][example_name]\n",
    "        return example['embeddings']\n",
    "\n",
    "\n",
    "    def validate_image(self, img):\n",
    "        img = np.array(img, dtype=float)\n",
    "        if len(img.shape) < 3:\n",
    "            rgb = np.empty((64, 64, 3), dtype=np.float32)\n",
    "            rgb[:, :, 0] = img\n",
    "            rgb[:, :, 1] = img\n",
    "            rgb[:, :, 2] = img\n",
    "            img = rgb\n",
    "\n",
    "        return img.transpose(2, 0, 1)\n",
    "\n",
    "################ txt2image_dataset.py ends here ###################\n",
    "\n",
    "################ utils.py ###################\n",
    "\n",
    "class Concat_embed(nn.Module):\n",
    "    def __init__(self, embed_dim, projected_embed_dim):\n",
    "        super(Concat_embed, self).__init__()\n",
    "        self.projection = nn.Sequential(nn.Linear(in_features=embed_dim, out_features=projected_embed_dim),\n",
    "                                        nn.BatchNorm1d(num_features=projected_embed_dim),\n",
    "                                        nn.LeakyReLU(negative_slope=0.2, inplace=True))\n",
    "\n",
    "    def forward(self, inp, embed):\n",
    "        projected_embed = self.projection(embed)\n",
    "        replicated_embed = projected_embed.repeat(4, 4, 1, 1).permute(2, 3, 0, 1)\n",
    "        hidden_concat = torch.cat([inp, replicated_embed], 1)\n",
    "\n",
    "        return hidden_concat\n",
    "\n",
    "class Utils(object):\n",
    "    def __init__(self, cuda):\n",
    "        self.is_cuda = cuda\n",
    "\n",
    "    def cuda(self, variable):\n",
    "        return variable.cuda() if self.is_cuda else variable\n",
    "\n",
    "    @staticmethod\n",
    "    def smooth_label(tensor, offset):\n",
    "        return tensor + offset\n",
    "\n",
    "    @staticmethod\n",
    "    def save_checkpoint(netD, netG, dir_path, epoch):\n",
    "        path = dir_path #os.path.join(dir_path, subdir_path)\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "        torch.save(netD.state_dict(), '{0}/disc_{1}.pth'.format(path, epoch))\n",
    "        torch.save(netG.state_dict(), '{0}/gen_{1}.pth'.format(path, epoch))\n",
    "        \n",
    "    @staticmethod\n",
    "    def weights_init(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find('Conv') != -1:\n",
    "            m.weight.data.normal_(0.0, 0.02)\n",
    "        elif classname.find('BatchNorm') != -1:\n",
    "            m.weight.data.normal_(1.0, 0.02)\n",
    "            m.bias.data.fill_(0)\n",
    "\n",
    "################ utils.py ends here ###################\n",
    "\n",
    "################ vae.py ###################\n",
    "\n",
    "class vae_encoder_generator(nn.Module):\n",
    "    def __init__(self, ngf):\n",
    "        super(vae_encoder_generator, self).__init__()\n",
    "        self.vae_encoder = vae_encoder(ngf)\n",
    "        self.vae_generator = vae_generator(ngf)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        x = self.vae_encoder(inp)\n",
    "        x = self.vae_generator(x)\n",
    "        return x\n",
    "\n",
    "    def generator_only(self, latent):\n",
    "        return self.vae_generator(latent)\n",
    "\n",
    "    def encoder_only(self, inp):\n",
    "        return self.vae_encoder(inp.cuda())\n",
    "\n",
    "\n",
    "class vae_generator(nn.Module):\n",
    "    def __init__(self, ngf):\n",
    "        super(vae_generator, self).__init__()\n",
    "        self.image_size = 64\n",
    "        self.num_channels = 3\n",
    "        self.noise_dim = 100\n",
    "        self.embed_dim = 1024\n",
    "        self.projected_embed_dim = 128\n",
    "        self.latent_dim = self.noise_dim + self.projected_embed_dim\n",
    "        self.ngf = ngf\n",
    "\n",
    "        # self.projection = nn.Sequential(nn.Linear(in_features=self.embed_dim, out_features=self.projected_embed_dim),\n",
    "        #     nn.BatchNorm1d(num_features=self.projected_embed_dim), nn.LeakyReLU(negative_slope=0.2, inplace=True))\n",
    "\n",
    "        # based on: https://github.com/pytorch/examples/blob/master/dcgan/main.py\n",
    "        self.netG = nn.Sequential(\n",
    "            nn.ConvTranspose2d(self.latent_dim, self.ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(self.ngf * 8),\n",
    "            nn.ReLU(True), # state size. (ngf*8) x 4 x 4\n",
    "\n",
    "            nn.ConvTranspose2d(self.ngf * 8, self.ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ngf * 4),\n",
    "            nn.ReLU(True), # state size. (ngf*4) x 8 x 8\n",
    "\n",
    "            nn.ConvTranspose2d(self.ngf * 4, self.ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ngf * 2),\n",
    "            nn.ReLU(True), # state size. (ngf*2) x 16 x 16\n",
    "\n",
    "            nn.ConvTranspose2d(self.ngf * 2, self.ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ngf),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(self.ngf, self.num_channels, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (num_channels) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, latent_vector):\n",
    "        # projected_embed = self.projection(embed_vector).unsqueeze(2).unsqueeze(3)\n",
    "        # latent_vector = torch.cat([projected_embed, z], 1)\n",
    "        latent_vector = latent_vector.view(-1, self.latent_dim, 1, 1)\n",
    "        #print(\"**** latent_vector is cuda = \",latent_vector.cpu().is_cuda)\n",
    "        output = self.netG(latent_vector.cpu())\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class vae_encoder(nn.Module):\n",
    "    def __init__(self, ngf):\n",
    "        super(vae_encoder, self).__init__()\n",
    "        self.image_size = 64\n",
    "        self.num_channels = 3\n",
    "        self.embed_dim = 1024\n",
    "        self.noise_dim = 100\n",
    "        self.projected_embed_dim = 128\n",
    "        self.latent_dim = self.noise_dim + self.projected_embed_dim\n",
    "        self.ngf = ngf\n",
    "\n",
    "        self.projection = nn.Sequential(nn.Linear(in_features=self.embed_dim, out_features=self.projected_embed_dim),\n",
    "            nn.BatchNorm1d(num_features=self.projected_embed_dim), nn.LeakyReLU(negative_slope=0.2, inplace=True))\n",
    "\n",
    "        # based on: https://github.com/pytorch/examples/blob/master/dcgan/main.py\n",
    "        self.netE = nn.Sequential(\n",
    "            # state size. (num_channels) x 64 x 64\n",
    "            nn.Conv2d(self.num_channels, self.ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ngf),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.Conv2d(self.ngf, self.ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.Conv2d(self.ngf * 2, self.ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.Conv2d(self.ngf * 4, self.ngf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.Conv2d(self.ngf * 8, self.latent_dim, 4, 1, 0, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, images):\n",
    "        output = self.netE(images)\n",
    "        #print(output.is_cuda)\n",
    "        return output\n",
    "\n",
    "\n",
    "class vae_discriminator(nn.Module):\n",
    "    def __init__(self, remove_noise):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.image_size = 64\n",
    "        self.num_channels = 128\n",
    "        self.embed_dim = 1024\n",
    "        if remove_noise:\n",
    "            self.projected_embed_dim = 228\n",
    "            self.noise_dim = 0\n",
    "        else:\n",
    "            self.projected_embed_dim = 128\n",
    "            self.noise_dim = 100\n",
    "        self.B_dim = 128\n",
    "        self.C_dim = 16\n",
    "        self.minibatch_discriminator = minibatch_discriminator(self.num_channels, self.B_dim, self.C_dim)\n",
    "        #\n",
    "        self.netD_1 = nn.Sequential(\n",
    "            nn.Linear(self.projected_embed_dim + self.noise_dim, 228),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(228, 128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "        self.netD_2 = nn.Sequential(\n",
    "            nn.Linear(128 + self.B_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, inp):\n",
    "        x = inp.view(-1, self.projected_embed_dim + self.noise_dim)\n",
    "        x = self.netD_1(x)\n",
    "        x = self.minibatch_discriminator(x)\n",
    "        x = self.netD_2(x)\n",
    "\n",
    "        return x.view(-1)\n",
    "\n",
    "################ vae.py ends here ###################\n",
    "\n",
    "################ gan_cls.py ###################\n",
    "\n",
    "class generator(nn.Module):\n",
    "    def __init__(self, remove_noise, variational):\n",
    "        super(generator, self).__init__()\n",
    "        self.image_size = 64\n",
    "        self.num_channels = 3\n",
    "        self.embed_dim = 1024\n",
    "        self.remove_noise = remove_noise\n",
    "        if remove_noise:\n",
    "            self.noise_dim = 0\n",
    "            self.projected_embed_dim = 228\n",
    "        else:\n",
    "            self.noise_dim = 100\n",
    "            self.projected_embed_dim = 128\n",
    "        self.latent_dim = self.noise_dim + self.projected_embed_dim\n",
    "        self.ngf = 64\n",
    "        self.variational = variational\n",
    "        self.mu = None\n",
    "        self.sd = None\n",
    "\n",
    "        self.projection = nn.Sequential(nn.Linear(in_features=self.embed_dim, out_features=self.projected_embed_dim),\n",
    "            nn.BatchNorm1d(num_features=self.projected_embed_dim), nn.LeakyReLU(negative_slope=0.2, inplace=True))\n",
    "\n",
    "        if variational:\n",
    "            self.en_mu = nn.Conv2d(self.projected_embed_dim, self.projected_embed_dim, 1, 1, 0)\n",
    "            self.en_sigma = nn.Conv2d(self.projected_embed_dim, self.projected_embed_dim, 1, 1, 0)\n",
    "            self.softplus = nn.Softplus()\n",
    "            self.en_mu.weight.data.normal_(0, 0.002)\n",
    "            self.en_mu.bias.data.normal_(0, 0.002)\n",
    "            self.en_sigma.weight.data.normal_(0, 0.002)\n",
    "            self.en_sigma.bias.data.normal_(0, 0.002)\n",
    "\n",
    "        # based on: https://github.com/pytorch/examples/blob/master/dcgan/main.py\n",
    "        self.netG = nn.Sequential(nn.ConvTranspose2d(self.latent_dim, self.ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(self.ngf * 8), nn.ReLU(True), # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(self.ngf * 8, self.ngf * 4, 4, 2, 1, bias=False), nn.BatchNorm2d(self.ngf * 4),\n",
    "            nn.ReLU(True), # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(self.ngf * 4, self.ngf * 2, 4, 2, 1, bias=False), nn.BatchNorm2d(self.ngf * 2),\n",
    "            nn.ReLU(True), # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(self.ngf * 2, self.ngf, 4, 2, 1, bias=False), nn.BatchNorm2d(self.ngf), nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(self.ngf, self.num_channels, 4, 2, 1, bias=False), nn.Tanh()\n",
    "            # state size. (num_channels) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, embed_vector, z, noise):\n",
    "        return self.netG(self.encoder_only(embed_vector, z, noise))\n",
    "\n",
    "    def encoder_only(self, embed_vector, z, noise):\n",
    "        projected_embed = self.projection(embed_vector).unsqueeze(2).unsqueeze(3)\n",
    "        if self.variational:\n",
    "            self.mu = self.en_mu(projected_embed)\n",
    "            self.sd = self.softplus(self.en_sigma(projected_embed))\n",
    "            projected_embed = self.mu + self.sd.mul(noise)\n",
    "        if self.remove_noise:\n",
    "            latent_vector = projected_embed\n",
    "        else:\n",
    "            latent_vector = torch.cat([projected_embed, z], 1)\n",
    "        return latent_vector\n",
    "\n",
    "    def generator_only(self, latent_vector):\n",
    "        return self.netG(latent_vector)\n",
    "\n",
    "\n",
    "class discriminator(nn.Module):\n",
    "    def __init__(self, remove_noise):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.image_size = 64\n",
    "        self.num_channels = 3\n",
    "        self.embed_dim = 1024\n",
    "        if remove_noise:\n",
    "            self.projected_embed_dim = 228\n",
    "        else:\n",
    "            self.projected_embed_dim = 128\n",
    "        self.ndf = 64\n",
    "        self.B_dim = 128\n",
    "        self.C_dim = 16\n",
    "\n",
    "        self.netD_1 = nn.Sequential(# input is (nc) x 64 x 64\n",
    "            nn.Conv2d(self.num_channels, self.ndf, 4, 2, 1, bias=False), nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(self.ndf, self.ndf * 2, 4, 2, 1, bias=False), nn.BatchNorm2d(self.ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True), # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(self.ndf * 2, self.ndf * 4, 4, 2, 1, bias=False), nn.BatchNorm2d(self.ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True), # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(self.ndf * 4, self.ndf * 8, 4, 2, 1, bias=False), nn.BatchNorm2d(self.ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True), )\n",
    "\n",
    "        self.projector = Concat_embed(self.embed_dim, self.projected_embed_dim)\n",
    "\n",
    "        self.netD_2 = nn.Sequential(# state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(self.ndf * 8 + self.projected_embed_dim, 1, 4, 1, 0, bias=False), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, inp, embed):\n",
    "        x_intermediate = self.netD_1(inp)\n",
    "        x = self.projector(x_intermediate, embed)\n",
    "        x = self.netD_2(x)\n",
    "\n",
    "        return x.view(-1, 1).squeeze(1), x_intermediate\n",
    "\n",
    "################ gan_cls.py ends here ###################\n",
    "\n",
    "################ gan_factory.py ###################\n",
    "\n",
    "class gan_factory(object):\n",
    "    @staticmethod\n",
    "    def generator_factory(type, ngf, remove_noise, variational=False):\n",
    "        if type == 'gan':\n",
    "            return generator(remove_noise, variational)\n",
    "        elif type == 'vae':\n",
    "            return vae_encoder_generator(ngf)\n",
    "\n",
    "    @staticmethod\n",
    "    def discriminator_factory(type, remove_noise):\n",
    "        if type == 'gan':\n",
    "            return discriminator(remove_noise)\n",
    "        elif type == 'vae':\n",
    "            return vae_discriminator(remove_noise)\n",
    "\n",
    "################ gan_factory.py ends here ###################\n",
    "\n",
    "################ trainer.py ###################\n",
    "\n",
    "class Trainer(object):\n",
    "    def __init__(self, type, dataset, split, lr, diter, vis_screen, save_path, l1_coef, l2_coef, pre_trained_gen,\n",
    "                 pre_trained_disc, batch_size, num_workers, epochs, args, params_search=False):\n",
    "        self.config = args\n",
    "        self.cuda = torch.cuda.is_available()\n",
    "\n",
    "        self.generator = gan_factory.generator_factory(type, args.ngf, args.remove_noise_2, args.variational)\n",
    "        self.discriminator = gan_factory.discriminator_factory(type, args.remove_noise_2)\n",
    "\n",
    "        self.target_generator = gan_factory.generator_factory(args.target_type, args.ngf, args.remove_noise_2)\n",
    "        \n",
    "        if self.cuda:\n",
    "            self.generator = self.generator.cuda()\n",
    "            self.discriminator = self.discriminator.cuda()\n",
    "\n",
    "        if pre_trained_disc:\n",
    "            print('loading {} from {}'.format('discriminator', pre_trained_disc))\n",
    "            self.discriminator.load_state_dict(torch.load(pre_trained_disc))\n",
    "        else:\n",
    "            if not params_search:\n",
    "                print('creating fresh params for {}'.format('discriminator'))\n",
    "            self.discriminator.apply(Utils.weights_init)\n",
    "\n",
    "        if pre_trained_gen:\n",
    "            print('loading {} from {}'.format('generator', pre_trained_gen))\n",
    "            self.generator.load_state_dict(torch.load(pre_trained_gen))\n",
    "        else:\n",
    "            if not params_search:\n",
    "                print('creating fresh params for {}'.format('generator'))\n",
    "            self.generator.apply(Utils.weights_init)\n",
    "\n",
    "        if dataset == 'flowers_only':\n",
    "            self.dataset = Text2ImageDataset(self.config.flowers_dataset_path, split=0)\n",
    "            self.target_dataset = Text2ImageDataset(self.config.flowers_dataset_path, split=2)\n",
    "        else:\n",
    "            print('Dataset not supported, please select either birds, flowers or flowers_only.')\n",
    "            exit()\n",
    "\n",
    "        self.noise_dim = 100\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.lr = lr\n",
    "        self.beta1 = 0.5\n",
    "        self.num_epochs = epochs\n",
    "        self.DITER = diter\n",
    "\n",
    "        self.l1_coef = l1_coef\n",
    "        self.l2_coef = l2_coef\n",
    "\n",
    "        self.data_loader = DataLoader(self.dataset, batch_size=self.batch_size, shuffle=True,\n",
    "                                      num_workers=self.num_workers)\n",
    "        self.target_data_loader = DataLoader(self.target_dataset, batch_size=self.batch_size, shuffle=True,\n",
    "                                             num_workers=self.num_workers)\n",
    "\n",
    "        self.optimD = torch.optim.Adam(self.discriminator.parameters(), lr=self.lr, betas=(self.beta1, 0.999))\n",
    "        self.optimG = torch.optim.Adam(self.generator.parameters(), lr=self.lr, betas=(self.beta1, 0.999))\n",
    "\n",
    "        self.save_path = save_path\n",
    "        self.type = type\n",
    "        # self.h_el = args.h_el\n",
    "        self.args = args\n",
    "        if not params_search:\n",
    "            self.checkpoints_path = 'tmp/'\n",
    "            if not os.path.exists(self.checkpoints_path):\n",
    "                os.makedirs(self.checkpoints_path)\n",
    "            print(\"***Calling Nearest Neighbour***\")\n",
    "            self.nn = NearestNeighbor(self.target_data_loader, dataset, self.cuda, args.ngf)\n",
    "        self.params_search = params_search\n",
    "        \n",
    "    def train(self, cls=False):\n",
    "        print(\"*** Inside train() func ***\")\n",
    "        if self.type == 'gan':\n",
    "            self._train_gan(cls)\n",
    "        \n",
    "    def _train_gan(self, cls):\n",
    "        print(\"*** Inside _train_gan() func ***\")\n",
    "        criterion = nn.BCELoss()\n",
    "        l2_loss = nn.MSELoss()\n",
    "        l1_loss = nn.L1Loss()\n",
    "        iteration = 0\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "            for sample in self.data_loader:\n",
    "                iteration += 1\n",
    "                right_images = sample['right_images']\n",
    "                right_embed = sample['right_embed']\n",
    "                wrong_images = sample['wrong_images']\n",
    "\n",
    "                right_images = Variable(right_images.float()).cuda()\n",
    "                right_embed = Variable(right_embed.float()).cuda()\n",
    "                wrong_images = Variable(wrong_images.float()).cuda()\n",
    "\n",
    "                real_labels = torch.ones(right_images.size(0))\n",
    "                fake_labels = torch.zeros(right_images.size(0))\n",
    "\n",
    "                # ======== One sided label smoothing ==========\n",
    "                # Helps preventing the discriminator from overpowering the\n",
    "                # generator adding penalty when the discriminator is too confident\n",
    "                # =============================================\n",
    "                smoothed_real_labels = torch.FloatTensor(Utils.smooth_label(real_labels.numpy(), -0.1))\n",
    "\n",
    "                real_labels = Variable(real_labels).cuda()\n",
    "                smoothed_real_labels = Variable(smoothed_real_labels).cuda()\n",
    "                fake_labels = Variable(fake_labels).cuda()\n",
    "\n",
    "                # Train the discriminator\n",
    "                self.discriminator.zero_grad()\n",
    "                outputs, activation_real = self.discriminator(right_images, right_embed)\n",
    "                real_loss = criterion(outputs, smoothed_real_labels)\n",
    "                real_score = outputs\n",
    "\n",
    "                if cls:\n",
    "                    outputs, _ = self.discriminator(wrong_images, right_embed)\n",
    "                    wrong_loss = criterion(outputs, fake_labels)\n",
    "                    wrong_score = outputs\n",
    "\n",
    "                if self.args.remove_noise:\n",
    "                    noise = Variable(torch.zeros(right_images.size(0), self.noise_dim)).cuda()\n",
    "                else:\n",
    "                    noise = Variable(torch.randn(right_images.size(0), self.noise_dim)).cuda()\n",
    "                noise = noise.view(noise.size(0), 100, 1, 1)\n",
    "                fake_images = self.generator(right_embed, noise, noise)\n",
    "                outputs, _ = self.discriminator(fake_images, right_embed)\n",
    "                fake_loss = criterion(outputs, fake_labels)\n",
    "                fake_score = outputs\n",
    "\n",
    "                d_loss = real_loss + fake_loss\n",
    "\n",
    "                if cls:\n",
    "                    d_loss = d_loss + wrong_loss\n",
    "\n",
    "                d_loss.backward()\n",
    "                self.optimD.step()\n",
    "\n",
    "                # Train the generator\n",
    "                self.generator.zero_grad()\n",
    "                if self.args.remove_noise:\n",
    "                    noise = Variable(torch.zeros(right_images.size(0), self.noise_dim)).cuda()\n",
    "                else:\n",
    "                    noise = Variable(torch.randn(right_images.size(0), self.noise_dim)).cuda()\n",
    "                noise = noise.view(noise.size(0), 100, 1, 1)\n",
    "                fake_images = self.generator(right_embed, noise, noise)\n",
    "                outputs, activation_fake = self.discriminator(fake_images, right_embed)\n",
    "                _, activation_real = self.discriminator(right_images, right_embed)\n",
    "\n",
    "                activation_fake = torch.mean(activation_fake, 0)\n",
    "                activation_real = torch.mean(activation_real, 0)\n",
    "\n",
    "                # ======= Generator Loss function============\n",
    "                # This is a customized loss function, the first term is the regular cross entropy loss\n",
    "                # The second term is feature matching loss, this measure the distance between the real and generated\n",
    "                # images statistics by comparing intermediate layers activations\n",
    "                # The third term is L1 distance between the generated and real images, this is helpful for the conditional case\n",
    "                # because it links the embedding feature vector directly to certain pixel values.\n",
    "                # ===========================================\n",
    "                g_loss = criterion(outputs, real_labels) +\\\n",
    "                         self.l2_coef * l2_loss(activation_fake, activation_real.detach()) +\\\n",
    "                         self.l1_coef * l1_loss(fake_images, right_images)\n",
    "\n",
    "                g_loss.backward()\n",
    "                self.optimG.step()\n",
    "\n",
    "                if iteration % 10 == 0:\n",
    "                    print(\"Epoch: %d, d_loss= %f, g_loss= %f, ccaD(X)= %f, D(G(X))= %f\" % (epoch, d_loss.data.cpu().mean(), g_loss.data.cpu().mean(), real_score.data.cpu().mean(), fake_score.data.cpu().mean()))\n",
    "\n",
    "            if (epoch) % 10 == 0:\n",
    "                Utils.save_checkpoint(self.discriminator, self.generator, self.save_path, epoch)\n",
    "                \n",
    "    def test(self):\n",
    "        self.generator.eval()\n",
    "        self.target_generator.eval()\n",
    "        number_of_images = 2\n",
    "        sample = next(iter(self.data_loader))\n",
    "        all_nn_texts = []\n",
    "        all_nn_images = []\n",
    "        all_fake_sources = []\n",
    "        all_transfers = []\n",
    "        text = sample['txt']\n",
    "        right_images = sample['right_images']\n",
    "        right_embed = sample['right_embed']\n",
    "        for i in range(number_of_images):\n",
    "            right_images_v = Variable(right_images.float(), volatile=True)\n",
    "            right_embed_v = Variable(right_embed.float(), volatile=True)\n",
    "            if self.args.remove_noise:\n",
    "                noise = Variable(torch.zeros(right_images_v.size(0), self.noise_dim), volatile=True)\n",
    "            else:\n",
    "                noise = Variable(torch.randn(right_images_v.size(0), self.noise_dim), volatile=True)\n",
    "            if self.cuda:\n",
    "                right_embed_v = right_embed_v.cuda()\n",
    "                noise = noise.cuda()\n",
    "\n",
    "            noise = noise.view(noise.size(0), self.noise_dim, 1, 1)\n",
    "            #print(\"right_embed_v type = \",type(right_embed_v),\"noise = \",type(noise))\n",
    "            fake_target = self.target_generator.generator_only(self.generator.encoder_only(right_embed_v, noise, noise))\n",
    "            all_transfers.append(fake_target)\n",
    "            fake_source = self.generator(right_embed_v, noise,noise)\n",
    "            all_fake_sources.append(fake_source)\n",
    "            \n",
    "            fake_source = fake_source.cuda()\n",
    "            print(\"fake_source shape: \",fake_source.detach().shape)\n",
    "            print(\"text description: \",text[0])\n",
    "            plt.imshow(fake_source[0].cpu().detach().permute(1, 2, 0))\n",
    "            plt.show()\n",
    "\n",
    "            nn_text, nn_images = self.nn.get_text_and_images(fake_target, -1)\n",
    "            all_nn_texts.append(nn_text)\n",
    "            all_nn_images.append(nn_images)\n",
    "            \n",
    "        for i, sentence in enumerate(text):\n",
    "            nn_sentences = [sents[i] for sents in all_nn_texts]\n",
    "            print(\"\\ncombined text: \",i,\"original sentence: \",sentence,\"nn_sentences: \",nn_sentences)\n",
    "\n",
    "        for i, image in enumerate(right_images):\n",
    "            nn_images = [imgs[i] for imgs in all_nn_images]\n",
    "            fake_source_images = [imgs[i].data.cpu().numpy() for imgs in all_fake_sources]\n",
    "            transfers_images = [imgs[i].data.cpu().numpy() for imgs in all_transfers]\n",
    "            image_tile = np.tile(image, (len(nn_images), 1, 1, 1))\n",
    "            #self.logger.draw_test(image_tile, fake_source_images, transfers_images, nn_images, 'image {}'.format(i))\n",
    "        print(\"*** end of testing ***\")\n",
    "   \n",
    "################ trainer.py ends here ###################\n",
    "\n",
    "################ runtime.py ###################\n",
    "class Struct:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "        \n",
    "parser = argparse.ArgumentParser()\n",
    "params = dict()\n",
    "\n",
    "params['type']='gan' #change this if you want to train any other gan\n",
    "params['target_type']='vae'\n",
    "params['lr']=0.0002\n",
    "params['l1_coef']=50\n",
    "params['l2_coef']=100\n",
    "params['diter']=5\n",
    "params['cls']=False\n",
    "params['save_path']='tmp/'\n",
    "params['inference']=False\n",
    "params['target_train']=False\n",
    "params['dataset']='flowers_only'\n",
    "params['split']=0\n",
    "params['batch_size']=128\n",
    "params['num_workers']=1\n",
    "params['ngf']=64\n",
    "params['epochs']=1\n",
    "params['remove_noise']=False\n",
    "params['remove_noise_2']=False\n",
    "params['variational']=False\n",
    "params['vis_screen']=False\n",
    "params['pre_trained_disc']=False\n",
    "params['pre_trained_gen']=False\n",
    "params['flowers_dataset_path']=\"../input/flowershd5dataset/flowers-hd5/data/flowers/flowers.hdf5\"\n",
    "\n",
    "args = Struct(**params) #Convert nested Python dict to object\n",
    "\n",
    "trainer = Trainer(type=args.type, dataset=args.dataset, split=args.split, lr=args.lr, diter=args.diter,\n",
    "                  vis_screen=args.vis_screen, save_path=args.save_path, l1_coef=args.l1_coef, \n",
    "                  l2_coef=args.l2_coef,pre_trained_disc=args.pre_trained_disc, \n",
    "                  pre_trained_gen=args.pre_trained_gen, batch_size=args.batch_size, \n",
    "                  num_workers=args.num_workers, epochs=args.epochs, args=args)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "if not args.inference:\n",
    "    if args.target_train:\n",
    "        trainer.target_train(args.cls)\n",
    "    else:\n",
    "        trainer.train(args.cls)\n",
    "print(\"*** Calling test() ***\")\n",
    "trainer.test()\n",
    "\n",
    "elapsed = str(timedelta(seconds=int(time.time() - start_time)))\n",
    "print('Running {} took {}'.format(\"GAN-CLS\", elapsed))\n",
    "\n",
    "################ runtime.py ends here ###################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
